{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"credit.csv\"\n",
    "data = pd.read_csv(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = data[data['Class'] == 1] \n",
    "valid = data[data['Class'] == 0] \n",
    "outlierFraction = len(fraud)/float(len(valid)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = data.corr() \n",
    "fig = plt.figure(figsize = (12, 9)) \n",
    "sns.heatmap(corrmat, vmax = .8, square = True) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Class'], axis = 1) \n",
    "Y = data[\"Class\"] \n",
    "xData = X.values \n",
    "yData = Y.values \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split( \n",
    "        xData, yData, test_size = 0.2, random_state = 42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier() \n",
    "rfc.fit(xTrain, yTrain) \n",
    "yPred = rfc.predict(xTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score  \n",
    "from sklearn.metrics import precision_score, recall_score \n",
    "from sklearn.metrics import f1_score, matthews_corrcoef \n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "\n",
    "n_outliers = len(fraud) \n",
    "n_errors = (yPred != yTest).sum() \n",
    "\n",
    "  \n",
    "acc = accuracy_score(yTest, yPred) \n",
    "prec = precision_score(yTest, yPred) \n",
    "rec = recall_score(yTest, yPred) \n",
    "f1 = f1_score(yTest, yPred) \n",
    "MCC = matthews_corrcoef(yTest, yPred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Normal', 'Fraud'] \n",
    "conf_matrix = confusion_matrix(yTest, yPred) \n",
    "plt.figure(figsize =(12, 12)) \n",
    "sns.heatmap(conf_matrix, xticklabels = LABELS,  \n",
    "            yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix\") \n",
    "plt.ylabel('True class') \n",
    "plt.xlabel('Predicted class') \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
